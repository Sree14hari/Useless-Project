{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfbdab48",
   "metadata": {},
   "source": [
    "Code To Augment Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\albumentations\\core\\validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "C:\\Users\\sreeh\\AppData\\Local\\Temp\\ipykernel_28412\\1663660347.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 source images. Starting augmentation...\n",
      "  -> Augmenting '1.jpg'...\n",
      "  -> Augmenting '2.jpg'...\n",
      "  -> Augmenting '3.jpg'...\n",
      "  -> Augmenting '4.jpg'...\n",
      "  -> Augmenting '5.jpg'...\n",
      "  -> Augmenting '6.jpg'...\n",
      "  -> Augmenting '7.jpg'...\n",
      "  -> Augmenting 'home-vada.png'...\n",
      "  -> Augmenting 'tst_vada.jpg'...\n",
      "\n",
      "Done! ✅ Generated 306 images in the 'augmented_vadas' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_DIR = \"masked\"\n",
    "OUTPUT_DIR = \"augmented_masked\"\n",
    "# We need ~33 augmentations per image to reach 300. Let's make it 34.\n",
    "# Total images will be 9 * 34 = 306.\n",
    "TARGET_COUNT_PER_IMAGE = 34\n",
    "\n",
    "# --- Define the Augmentation Pipeline ---\n",
    "# This pipeline applies a series of random transformations to each image.\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.06, scale_limit=0.1, rotate_limit=45, p=0.8),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "    A.GaussNoise(var_limit=(10.0, 50.0), p=0.5),\n",
    "    A.MotionBlur(blur_limit=7, p=0.5)\n",
    "])\n",
    "\n",
    "# --- Main Script ---\n",
    "def augment_images():\n",
    "    \"\"\"\n",
    "    Reads images from INPUT_DIR, applies augmentations, and saves them to OUTPUT_DIR.\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        image_files = [f for f in os.listdir(INPUT_DIR) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if not image_files:\n",
    "            print(f\"Error: No images found in the '{INPUT_DIR}' directory.\")\n",
    "            return\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input directory '{INPUT_DIR}' not found. Please create it.\")\n",
    "        return\n",
    "\n",
    "    total_generated = 0\n",
    "    print(f\"Found {len(image_files)} source images. Starting augmentation...\")\n",
    "\n",
    "    # Loop through each source image\n",
    "    for filename in image_files:\n",
    "        image_path = os.path.join(INPUT_DIR, filename)\n",
    "        # Read the image using OpenCV\n",
    "        image = cv2.imread(image_path)\n",
    "        # Convert from BGR (OpenCV default) to RGB for Albumentations\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        print(f\"  -> Augmenting '{filename}'...\")\n",
    "\n",
    "        # Generate the target number of augmented versions\n",
    "        for i in range(TARGET_COUNT_PER_IMAGE):\n",
    "            # Apply the augmentation pipeline\n",
    "            augmented_data = transform(image=image)\n",
    "            augmented_image = augmented_data['image']\n",
    "\n",
    "            # Convert back to BGR to save with OpenCV\n",
    "            augmented_image_bgr = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Define the new filename and save the image\n",
    "            output_filename = f\"{base_filename}_aug_{i+1}.jpg\"\n",
    "            cv2.imwrite(os.path.join(OUTPUT_DIR, output_filename), augmented_image_bgr)\n",
    "            total_generated += 1\n",
    "\n",
    "    print(f\"\\nDone! ✅ Generated {total_generated} images in the '{OUTPUT_DIR}' folder.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    augment_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5761b05",
   "metadata": {},
   "source": [
    "Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c21ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# --- Configuration ---\n",
    "# Source folders containing your full augmented dataset\n",
    "SOURCE_IMAGES_DIR = \"augmented_images\"\n",
    "SOURCE_MASKS_DIR = \"augmented_masks\"\n",
    "\n",
    "# Destination folders to be created\n",
    "DEST_TRAIN_A = \"trainA\"  # 80% of real images\n",
    "DEST_TEST_A = \"testA\"    # 20% of real images\n",
    "DEST_TRAIN_B = \"trainB\"  # 80% of masks\n",
    "DEST_TEST_B = \"testB\"    # 20% of masks\n",
    "\n",
    "# Split ratio\n",
    "SPLIT_RATIO = 0.20\n",
    "\n",
    "# --- Main Script ---\n",
    "def create_final_dataset():\n",
    "    \"\"\"\n",
    "    Copies files from source augmented folders into a new, split\n",
    "    train/test structure required by the CycleGAN model.\n",
    "    \"\"\"\n",
    "    # Create all destination directories\n",
    "    for path in [DEST_TRAIN_A, DEST_TEST_A, DEST_TRAIN_B, DEST_TEST_B]:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Get the master list of filenames from the images folder\n",
    "    try:\n",
    "        filenames = os.listdir(SOURCE_IMAGES_DIR)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Source directory '{SOURCE_IMAGES_DIR}' not found.\")\n",
    "        return\n",
    "\n",
    "    # Shuffle the list to ensure a random split\n",
    "    random.shuffle(filenames)\n",
    "\n",
    "    # Calculate the split point\n",
    "    split_index = int(len(filenames) * (1 - SPLIT_RATIO))\n",
    "\n",
    "    # Divide the list into training and testing sets\n",
    "    train_files = filenames[:split_index]\n",
    "    test_files = filenames[split_index:]\n",
    "\n",
    "    print(\"Splitting files...\")\n",
    "\n",
    "    # Copy training files\n",
    "    for filename in train_files:\n",
    "        # Copy image to trainA\n",
    "        shutil.copy2(os.path.join(SOURCE_IMAGES_DIR, filename), os.path.join(DEST_TRAIN_A, filename))\n",
    "        # Copy corresponding mask to trainB\n",
    "        shutil.copy2(os.path.join(SOURCE_MASKS_DIR, filename), os.path.join(DEST_TRAIN_B, filename))\n",
    "\n",
    "    # Copy testing files\n",
    "    for filename in test_files:\n",
    "        # Copy image to testA\n",
    "        shutil.copy2(os.path.join(SOURCE_IMAGES_DIR, filename), os.path.join(DEST_TEST_A, filename))\n",
    "        # Copy corresponding mask to testB\n",
    "        shutil.copy2(os.path.join(SOURCE_MASKS_DIR, filename), os.path.join(DEST_TEST_B, filename))\n",
    "\n",
    "    print(\"\\nDone! ✅\")\n",
    "    print(f\"Total training images (trainA): {len(os.listdir(DEST_TRAIN_A))}\")\n",
    "    print(f\"Total testing images (testA):   {len(os.listdir(DEST_TEST_A))}\")\n",
    "    print(f\"Total training masks (trainB):  {len(os.listdir(DEST_TRAIN_B))}\")\n",
    "    print(f\"Total testing masks (testB):    {len(os.listdir(DEST_TEST_B))}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_final_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
